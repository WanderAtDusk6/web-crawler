# 网络爬虫引发的问题（这标题略蠢，，，）

# 爬虫的尺寸
小规模：
数据量小，爬取速度不敏感
**Requests库   |爬取网页

中规模：
数据规模较大，爬取速度敏感
**Scrapy库     | 爬取网站 爬取系列网站

大规模：
搜索引擎，爬取速度关键
定制开发       |  爬取全网

# 网络爬虫的限制
#1 来源审查：  判断user-Agent进行限制
#  检查来访的HTTP协议头的User-Agent域，只响应浏览器或友好爬虫的访问
#2 发布公告：Robots协议
#  告知所有爬虫网站的爬取策略，要求爬虫遵循
